### 9. **自然语言处理：Word2Vec的Skip-Gram模型**
**问题**：推导Skip-Gram的损失函数和负采样优化。
**答案**：
1. **目标函数**：$\log \sigma(v_{w_o}^T v_{w_i}) + \sum_{j=1}^k \log \sigma(-v_{w_j}^T v_{w_i})$；
2. **负采样**：随机选择负样本减少计算量；
3. **代码**（Gensim库）：
```python
from gensim.models import Word2Vec
model = Word2Vec(sentences, sg=1, negative=5)
```
